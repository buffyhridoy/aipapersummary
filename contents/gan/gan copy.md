---
id: wgan
title: 'Wasserstein Generative Adversarial Networks'
sidebar_label: 'WGAN'
keywords:

---

> Citations: 3,747 | Paper Published: 17 Jul 2017 | Institutions: Courant Institute of Mathematical Sciences, Facebook | Authors: Martin Arjovsky, Soumith Chintala, LÃ©on Bottou

<!-- Prettier doesn't change this -->

:::tip Abstract in 2 Lines

This paper introduces a new algorithm called WGAN for unsupervised learning. It improves the stability of learning, avoids mode collapse, and provides meaningful learning curves for debugging and hyperparameter searches.

:::


## Contributions

- Introducing a new algorithm called WGAN for unsupervised learning.
- Improving the stability of learning, getting rid of problems like mode collapse, and providing meaningful learning curves useful for debugging and hyperparameter searches.
- Providing extensive theoretical work highlighting the deep connections to different distances between distributions. 


## Practical Implications

The practical implications of this paper are that the WGAN algorithm can be used to improve the stability of unsupervised learning, avoid problems like mode collapse, and provide meaningful learning curves for debugging and hyperparameter searches. This can be useful in various applications such as image and speech recognition, natural language processing, and generative modeling.


## Methods

<!-- Prettier doesn't change this -->

:::info Methodology

In this paper, the authors proposed a new algorithm called WGAN for unsupervised learning. They provided a comprehensive theoretical analysis of how the Earth Mover (EM) distance behaves in comparison to popular probability distances and divergences used in the context of learning distributions. The authors used experiments to show that the WGAN algorithm improves the stability of learning, avoids problems like mode collapse, and provides meaningful learning curves for debugging and hyperparameter searches.

:::


## Data

The paper does not mention any specific dataset used in the experiments. However, the authors used experiments to evaluate the performance of the proposed WGAN algorithm.


## Results

<!-- Prettier doesn't change this -->

:::note Performance Analysis

-  A meaningful loss metric that correlates with the generator's convergence and sample quality.
- Improved stability of the optimization process.
- The authors also show that the WGAN algorithm can generate high-quality images with a resolution of 64x64 pixels, and that it outperforms the standard GAN formulation in terms of visual quality and stability. However, the paper does not provide specific performance values or metrics.

:::


## Limitations

- The experiments are limited to image generation tasks, and it is unclear how well the proposed algorithm would perform on other types of data.
- The paper does not provide a detailed analysis of the hyperparameters used in the experiments, which could limit the reproducibility of the results.
